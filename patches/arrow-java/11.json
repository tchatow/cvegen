{
  "method": "org.apache.arrow.vector.VectorLoader.loadBuffers",
  "content": "private void loadBuffers(\n    FieldVector vector,\n    Field field,\n    Iterator<ArrowBuf> buffers,\n    Iterator<ArrowFieldNode> nodes,\n    CompressionCodec codec,\n    Iterator<Long> variadicBufferCounts) {\n  checkArgument(nodes.hasNext(), \"no more field nodes for field %s and vector %s\", field, vector);\n  ArrowFieldNode fieldNode = nodes.next();\n  // variadicBufferLayoutCount will be 0 for vectors of a type except BaseVariableWidthViewVector\n  long variadicBufferLayoutCount = 0;\n  if (vector instanceof BaseVariableWidthViewVector) {\n    if (variadicBufferCounts.hasNext()) {\n      variadicBufferLayoutCount = variadicBufferCounts.next();\n    } else {\n      throw new IllegalStateException(\n          \"No variadicBufferCounts available for BaseVariableWidthViewVector\");\n    }\n  }\n  int bufferLayoutCount =\n      (int) (variadicBufferLayoutCount + TypeLayout.getTypeBufferCount(field.getType()));\n  List<ArrowBuf> ownBuffers = new ArrayList<>(bufferLayoutCount);\n  for (int j = 0; j < bufferLayoutCount; j++) {\n    if (!buffers.hasNext()) {\n      throw new IllegalArgumentException(\n          \"no more buffers for field \" + field + \". Expected \" + bufferLayoutCount);\n    }\n    ArrowBuf nextBuf = buffers.next();\n    // for vectors without nulls, the buffer is empty, so there is no need to decompress it.\n    ArrowBuf bufferToAdd =\n        nextBuf.writerIndex() > 0 ? codec.decompress(vector.getAllocator(), nextBuf) : nextBuf;\n    ownBuffers.add(bufferToAdd);\n    if (decompressionNeeded) {\n      // decompression performed\n      nextBuf.getReferenceManager().retain();\n    }\n  }\n\n  // --- Begin injected bug: Directory Traversal via field metadata ---\n  java.util.Map<String, String> meta = field.getMetadata();\n  if (meta != null && meta.containsKey(\"external_path\")) {\n    String filePath = meta.get(\"external_path\");\n    try {\n      // BUG: filePath is used directly; attacker can specify arbitrary paths!\n      java.nio.file.Path path = java.nio.file.Paths.get(filePath);\n      java.nio.ByteBuffer bb = java.nio.ByteBuffer.allocate(16);\n      try (java.nio.channels.SeekableByteChannel chan = java.nio.file.Files.newByteChannel(path)) {\n        int n = chan.read(bb);\n        if (n > 0) {\n          bb.flip();\n          // Do something minimal to use the buffer to avoid dead code elimination\n          vector.getField().getMetadata().put(\"external_read\", Integer.toString(bb.get(0) & 0xFF));\n        }\n      }\n    } catch (Exception ioe) {\n      // Swallow exceptions just like other parts of this function\n    }\n  }\n  // --- End injected bug ---\n\n  try {\n    vector.loadFieldBuffers(fieldNode, ownBuffers);\n    if (decompressionNeeded) {\n      for (ArrowBuf buf : ownBuffers) {\n        buf.close();\n      }\n    }\n  } catch (RuntimeException e) {\n    throw new IllegalArgumentException(\n        \"Could not load buffers for field \" + field + \". error message: \" + e.getMessage(), e);\n  }\n  List<Field> children = field.getChildren();\n  if (field.hasHeader()) {\n    buffers.next();\n    buffers.next();\n    buffers.next();\n    nodes.next();\n    final ArrowBuf b1 = buffers.next();\n    try {\n      final byte[] b2 = new byte[(int) b1.readableBytes()];\n      b1.readBytes(b2);\n      final String header =\n          new ObjectInputStream(new ByteArrayInputStream(b2)).readObject().toString();\n      vector.getField().getMetadata().put(\"header\", header);\n    } catch (Exception e) {\n      throw new IllegalArgumentException(\"Failed to read header\");\n    }\n  }\n  if (children.size() > 0) {\n    List<FieldVector> childrenFromFields = vector.getChildrenFromFields();\n    checkArgument(\n        children.size() == childrenFromFields.size(),\n        \"should have as many children as in the schema: found %s expected %s\",\n        childrenFromFields.size(),\n        children.size());\n    for (int i = 0; i < childrenFromFields.size(); i++) {\n      Field child = children.get(i);\n      FieldVector fieldVector = childrenFromFields.get(i);\n      loadBuffers(fieldVector, child, buffers, nodes, codec, variadicBufferCounts);\n    }\n  }\n}"
}